{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Sign Recognition Report\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Build a Traffic Sign Recognition Project\n",
    "\n",
    "###### The goals / steps of this project are:\n",
    "\n",
    "- Load the data set (see below for links to the project data set).\n",
    "\n",
    "- Explore, summarize and visualize the data set.\n",
    "\n",
    "- Design, train and test a model architecture.\n",
    "\n",
    "- Use the model to make predictions on new images.\n",
    "\n",
    "- Analyze the softmax probabilities of the new images.\n",
    "\n",
    "- Summarize the results with a written report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1) Dataset Summary:\n",
    "Using numpy I calculated the following:\n",
    "- Number of training examples.\n",
    "- Number of testing examples.\n",
    "- Number of validation examples.\n",
    "- Image data shape.\n",
    "- Number of classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Exploratory Visualization:\n",
    "To visualize the data:\n",
    "- A random image is plotted\n",
    "- The label is printed.\n",
    "- The type of the image is printed.\n",
    "- The maximum and minimum values of pixels the image are printed.\n",
    "- A chart of the number of images each class has is shown below.\n",
    "\n",
    "\n",
    " <img src=\"Report_pics/capture.JPG\" width=\"361\" alt=\"Combined Image\" /> \n",
    " <p style=\"text-align: center;\"> A chart showing the number of pictures per each class (above)</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3) Preprocessing: \n",
    "\n",
    "I chose to normalize the images, i.e. each pixel values were (0, 255) and was normalized to (0, 1). Augmenting the data set to roughly even the number of images per class would help a lot.\n",
    "\n",
    "**Note:** I tried gray scaling but the returned images gave me weird colors so I removed it. Also, I spent days searching for other ways to preprocess my data, but after increasing the batch size and the number of epochs my values reached 0.93 so I didn't add them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Model Architecture: \n",
    "\n",
    "I used a 5 layer LeNet architecture. I tried tuning the parameters, eventually I kept the values (mu = 0 and sigma = 0.1). The steps taken for LeNet architecture are:\n",
    "- **Layer 1:** Convolution with valid padding. Input = 32x32x3. Output = 28x28x6.\n",
    "- Relu activation.\n",
    "- MaxPooling. Input = 28x28x6. Output = 14x14x6.\n",
    "- **Layer 2:** Convolution with valid padding. Output = 10x10x16.\n",
    "- Relu activation.\n",
    "- MaxPooling. Input = 10x10x16. Output = 5x5x16.\n",
    "- Flatten. Input = 5x5x16. Output = 400.\n",
    "- **Layer 3:** Fully Connected. Input = 400. Output = 120.\n",
    "- Relu activation.\n",
    "- **Layer 4:** Fully Connected. Input = 120. Output = 84.\n",
    "- Relu activation.\n",
    "- **Layer 5:** Fully Connected. Input = 84. Output = 43.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Model Training: \n",
    "\n",
    "- The labels are one-hot encoded.\n",
    "- I used Adam optimizer and optimizer.minimize.\n",
    "- Number of epochs = 35.\n",
    "- Batch size = 256.\n",
    "- Learning rate = 0.001.\n",
    "- A plot of the loss and accuracy is below.\n",
    "\n",
    " <img src=\"Report_pics/capture2.png\" width=\"361\" alt=\"Combined Image\" />\n",
    " <p style=\"text-align: center;\"> Loss and accuracy (above)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Solution Approach:\n",
    "\n",
    "My final model results were:\n",
    "- Training set accuracy of 0.99908.\n",
    "- Validation set accuracy of 0.93878 the highest being 0.94014.\n",
    "- Test set accuracy of 0.92629\n",
    "\n",
    "I chose to use LeNet architecture. \"The LeNet architecture is straightforward and small, (in terms of memory footprint), making it perfect for teaching the basics of CNNs â€” it can even run on the CPU (if your system does not have a suitable GPU), making it a great 'first CNN'.\"  Adrian Rosebrock on August 1, 2016. LeNet gave a good accuracy after a certain number of epochs, this helped me to use less preprocessing techniques. Data augmentation would have helped the accuracy jump to above 0.95, I almost added it but ran out of time as researching and implementing many easy tasks took me too long, I decided to do the bare minimum and get back to enhancing and attempting challenges later.\n",
    "\n",
    "I adjusted my hyper parameters by trial and error. At the time I was using only 15 epochs to reduce the processing time as I'm using my CPU. After tuning I used 35 epochs and I got the required accuracy. Processing dose take long though, this wouldn't be the case if more preprocessing was applied. Training, validation and test accuracy were satisfying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Acquiring New Images:\n",
    "\n",
    "- The 20 images I found on the web were in PNG format, with dimensions (800, 704) so i had to resize them. \n",
    "- Each pixel had 4 color spaces, so I had to slice the last channel.\n",
    "- Each pixel was already ranging from (0.0, 1.0), luckily.\n",
    "- They shouldn't be difficult for detect as they are raw (i.e. not pictures taken from the street).\n",
    "- When reading the images using cv2.imread the colors were changed, that didn't happen when using mpimg.imread.\n",
    "- I had to manually color some gaps in white as they were read in black instead. \n",
    "\n",
    " <img src=\"Report_pics/all.png\" width=\"361\" alt=\"Combined Image\" /> \n",
    " <p style=\"text-align: center;\"> The 20 images I found on the web (above)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Performance on New Images:\n",
    "\n",
    "The results for the images I found on the web were between 0.7 and 0.85. The results are better on the test dataset, probably because reducing the size of the images wasted some information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Model Certainty - Softmax Probabilities:\n",
    "\n",
    "The model was very certain about some pictures giving probability 1.0 to the right classification. For a few pictures though it wasn't. Mostly the unrecognized pictures were the ones that lost some of their features when compressing, such as the slippery road sign shown below.\n",
    "\n",
    " <img src=\"Report_pics/capture3.png\" width=\"90\" alt=\"Combined Image\" />\n",
    "\n",
    " <p style=\"text-align: center;\"> The resized version of the slippery road sign (above)</p> \n",
    "\n",
    " <img src=\"Report_pics/capture4.png\" width=\"300\" alt=\"Combined Image\" />\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
